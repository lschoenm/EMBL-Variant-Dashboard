{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b49ff6f",
   "metadata": {},
   "source": [
    "# Fetching Gene and Associated Variant Data from EMBL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3e65e",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25f36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasschonmann/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import polars as pl\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import plotly.io as pio\n",
    "\n",
    "# Import src directory\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "SRC = NOTEBOOK_DIR.parent / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from helpers import chunks\n",
    "\n",
    "# Required for `nbconvert` to include Plotly plots in the output HTML\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb0de8",
   "metadata": {},
   "source": [
    "### Parameter Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89faa1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either the symbold or Ensembl gene ID to analyze\n",
    "GENE_ID = \"CYP2D6\"\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf2271",
   "metadata": {},
   "source": [
    "## Query EMBL Database for IDs\n",
    "\n",
    "This is helper code to look up an external symbol (e.g. a display name for a gene/transcript, a synonym, or an externally linked reference). It returns an EMBL ID. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181ec170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 entries for symbol 'CYP2D6' in species 'human':\n",
      "ID: ENSG00000100197, Type: gene\n",
      "ID: ENSG00000272000, Type: gene\n",
      "ID: ENSG00000272532, Type: gene\n",
      "ID: ENSG00000275211, Type: gene\n",
      "ID: ENSG00000280905, Type: gene\n",
      "ID: ENSG00000282966, Type: gene\n",
      "ID: ENSG00000283284, Type: gene\n",
      "ID: LRG_303, Type: gene\n"
     ]
    }
   ],
   "source": [
    "symbol = \"CYP2D6\"\n",
    "species = \"human\"\n",
    "\n",
    "BASE = \"https://rest.ensembl.org/\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "endpoint = \"xrefs/symbol/\" + species + \"/\" + symbol\n",
    "\n",
    "id = \"ENSG00000139618\"\n",
    "params = {}\n",
    "\n",
    "url = BASE + endpoint\n",
    "\n",
    "r = requests.get(url, params=params, headers=headers)\n",
    "try:\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(\"API Error:\", e)\n",
    "stats = r.json()\n",
    "\n",
    "if stats:\n",
    "    print(f\"Found {len(stats)} entries for symbol '{symbol}' in species '{species}':\")\n",
    "    for entry in sorted(stats, key=lambda x: x[\"id\"]):\n",
    "        print(f\"ID: {entry['id']}, Type: {entry['type']}\")\n",
    "else:\n",
    "    print(f\"No entries found for symbol '{symbol}' in species '{species}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffdd71",
   "metadata": {},
   "source": [
    "## Get Gene Region Based on a EMBL Stable ID or Gene Symbol\n",
    "\n",
    "Versatile wrapper function that searches the EMBL database for genes either based on an EMBL stable ID or a gene symbol + species. \n",
    "\n",
    "If the ID does not start with \"ENSG\" search must be set explicitly to IDs with `is_id=True`. \n",
    "\n",
    "Prints the most important information and returns the fetched object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66349884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene name: CYP2D6\n",
      "Gene ID: ENSG00000100197\n",
      "Description: cytochrome P450 family 2 subfamily D member 6 (gene/pseudogene) [Source:HGNC Symbol;Acc:HGNC:2625]\n",
      "Species: human\n",
      "Assembly name: GRCh38\n",
      "Chromosome: 22\n",
      "Start: 42125962\n",
      "End: 42131236\n",
      "Gene length: 5.28 kbp\n"
     ]
    }
   ],
   "source": [
    "def embl_lookup(name, species=\"human\", is_id=False, verbose=True):\n",
    "    # Determine if the input is an EMBL ID or a gene symbol\n",
    "    if is_id or name.startswith(\"ENSG\"):\n",
    "        type = \"id\"\n",
    "        species = \"\"\n",
    "    else:\n",
    "        type = \"symbol\"\n",
    "        species = species + \"/\"\n",
    "    BASE = \"https://rest.ensembl.org/\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    endpoint = \"lookup/\" + type + \"/\"\n",
    "\n",
    "    id = \"ENSG00000139618\"\n",
    "    params = {}\n",
    "\n",
    "    url = BASE + endpoint + species + name\n",
    "\n",
    "    r = requests.get(url, params=params, headers=headers)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(\"Gene not found.\")\n",
    "        print(\"API Error:\", e)\n",
    "        return\n",
    "    stats = r.json()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Gene name: {stats.get('display_name')}\")\n",
    "        print(f\"Gene ID: {stats.get('id')}\")\n",
    "        print(f\"Description: {stats.get('description')}\")\n",
    "        print(f\"Species: {stats.get('species')}\")\n",
    "        print(f\"Assembly name: {stats.get('assembly_name')}\")\n",
    "        print(f\"Chromosome: {stats.get('seq_region_name')}\")\n",
    "        print(f\"Start: {stats.get('start')}\")\n",
    "        print(f\"End: {stats.get('end')}\")\n",
    "\n",
    "        # Calculate gene length in kilobase pairs (kbp) and format to 2 decimal places\n",
    "        gene_length = stats.get(\"end\") - stats.get(\"start\") + 1\n",
    "        gene_length_kbp = f\"{gene_length / 1000:.2f}\"\n",
    "        print(f\"Gene length: {gene_length_kbp} kbp\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "gene_data = embl_lookup(GENE_ID, species=\"human\", is_id=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed49ff",
   "metadata": {},
   "source": [
    "## Fetch Variants for a Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c93d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_variants(name, species=\"human\", is_id=False, verbose=True):\n",
    "    gene_data = embl_lookup(name, species=species, is_id=is_id, verbose=verbose)\n",
    "    if not gene_data:\n",
    "        return\n",
    "\n",
    "    region = f\"{gene_data['seq_region_name']}:{gene_data['start']}-{gene_data['end']}\"\n",
    "    params = {\"feature\": \"variation\"}\n",
    "\n",
    "    BASE = \"https://rest.ensembl.org/\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    endpoint = \"overlap/region/\" + species + \"/\" + region\n",
    "\n",
    "    url = BASE + endpoint\n",
    "\n",
    "    r = requests.get(url, params=params, headers=headers)\n",
    "    try:\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(\"Unable to fetch variants.\")\n",
    "        print(\"API Error:\", e)\n",
    "        return None\n",
    "    stats = r.json()\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "variants = fetch_variants(name=GENE_ID, verbose=False)\n",
    "df_vars = pl.DataFrame(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d64f6",
   "metadata": {},
   "source": [
    "### Drop Multiallelic Variants and Transform Columns\n",
    "\n",
    "The table will be saved as a Parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b13209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1331 multiallelic or special variants.\n",
      "Remaining biallelic variants: 2451.\n",
      "Saved variant data to '../data/processed/CYP2D6-variants.parquet'.\n"
     ]
    }
   ],
   "source": [
    "# Drop multiallelic variants and special cases\n",
    "count_variants_all = df_vars.height\n",
    "df_vars = df_vars.filter(pl.col(\"alleles\").list.len() == 2)\n",
    "count_variants_biallelic = df_vars.height\n",
    "\n",
    "print(\n",
    "    f\"Dropped {count_variants_all - count_variants_biallelic} multiallelic or special variants.\"\n",
    ")\n",
    "print(f\"Remaining biallelic variants: {count_variants_biallelic}.\")\n",
    "\n",
    "# Select and rename relevant columns\n",
    "df_vars = df_vars.select(\n",
    "    [\n",
    "        pl.col(\"id\"),\n",
    "        pl.col(\"seq_region_name\").alias(\"chr\"),\n",
    "        pl.col(\"start\").alias(\"pos\"),\n",
    "        pl.col(\"alleles\").list.get(0).alias(\"ref\"),\n",
    "        pl.col(\"alleles\").list.get(1).alias(\"alt\"),\n",
    "        pl.col(\"consequence_type\").alias(\"consequence\"),\n",
    "        pl.col(\"clinical_significance\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write to Parquet file\n",
    "out_path = f\"../data/processed/{GENE_ID}-variants.parquet\"\n",
    "df_vars.write_parquet(out_path)\n",
    "print(f\"Saved variant data to '{out_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4e9e0",
   "metadata": {},
   "source": [
    "### Add Population Variant Details to Table\n",
    "\n",
    "Fetches the variant minor allele frequencies from EMBL for all populations and merges it with the main table information. This is rate-limited and can take a while (~20 minutes for a standard-sized gene). \n",
    "\n",
    "The long format table will be saved as a Parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af24fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2451/2451 variants"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>chr</th><th>pos</th><th>ref</th><th>alt</th><th>consequence</th><th>clinical_significance</th><th>population</th><th>minor_allele</th><th>MAF</th><th>most_severe_consequence</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>str</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;rs1219101811&quot;</td><td>&quot;22&quot;</td><td>42125963</td><td>&quot;G&quot;</td><td>&quot;A&quot;</td><td>&quot;3_prime_UTR_variant&quot;</td><td>[]</td><td>&quot;gnomADg:fin&quot;</td><td>null</td><td>1.0</td><td>&quot;splice_polypyrimidine_tract_va…</td></tr><tr><td>&quot;rs1219101811&quot;</td><td>&quot;22&quot;</td><td>42125963</td><td>&quot;G&quot;</td><td>&quot;A&quot;</td><td>&quot;3_prime_UTR_variant&quot;</td><td>[]</td><td>&quot;gnomADg:nfe&quot;</td><td>null</td><td>0.000015</td><td>&quot;splice_polypyrimidine_tract_va…</td></tr><tr><td>&quot;rs1219101811&quot;</td><td>&quot;22&quot;</td><td>42125963</td><td>&quot;G&quot;</td><td>&quot;A&quot;</td><td>&quot;3_prime_UTR_variant&quot;</td><td>[]</td><td>&quot;gnomADg:nfe&quot;</td><td>null</td><td>1.0</td><td>&quot;splice_polypyrimidine_tract_va…</td></tr><tr><td>&quot;rs1219101811&quot;</td><td>&quot;22&quot;</td><td>42125963</td><td>&quot;G&quot;</td><td>&quot;A&quot;</td><td>&quot;3_prime_UTR_variant&quot;</td><td>[]</td><td>&quot;gnomADg:mid&quot;</td><td>null</td><td>1.0</td><td>&quot;splice_polypyrimidine_tract_va…</td></tr><tr><td>&quot;rs1219101811&quot;</td><td>&quot;22&quot;</td><td>42125963</td><td>&quot;G&quot;</td><td>&quot;A&quot;</td><td>&quot;3_prime_UTR_variant&quot;</td><td>[]</td><td>&quot;gnomADg:amr&quot;</td><td>null</td><td>1.0</td><td>&quot;splice_polypyrimidine_tract_va…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌──────────────┬─────┬──────────┬─────┬───┬─────────────┬──────────────┬──────────┬────────────────┐\n",
       "│ id           ┆ chr ┆ pos      ┆ ref ┆ … ┆ population  ┆ minor_allele ┆ MAF      ┆ most_severe_co │\n",
       "│ ---          ┆ --- ┆ ---      ┆ --- ┆   ┆ ---         ┆ ---          ┆ ---      ┆ nsequence      │\n",
       "│ str          ┆ str ┆ i64      ┆ str ┆   ┆ str         ┆ str          ┆ f64      ┆ ---            │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ str            │\n",
       "╞══════════════╪═════╪══════════╪═════╪═══╪═════════════╪══════════════╪══════════╪════════════════╡\n",
       "│ rs1219101811 ┆ 22  ┆ 42125963 ┆ G   ┆ … ┆ gnomADg:fin ┆ null         ┆ 1.0      ┆ splice_polypyr │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ imidine_tract_ │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ va…            │\n",
       "│ rs1219101811 ┆ 22  ┆ 42125963 ┆ G   ┆ … ┆ gnomADg:nfe ┆ null         ┆ 0.000015 ┆ splice_polypyr │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ imidine_tract_ │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ va…            │\n",
       "│ rs1219101811 ┆ 22  ┆ 42125963 ┆ G   ┆ … ┆ gnomADg:nfe ┆ null         ┆ 1.0      ┆ splice_polypyr │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ imidine_tract_ │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ va…            │\n",
       "│ rs1219101811 ┆ 22  ┆ 42125963 ┆ G   ┆ … ┆ gnomADg:mid ┆ null         ┆ 1.0      ┆ splice_polypyr │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ imidine_tract_ │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ va…            │\n",
       "│ rs1219101811 ┆ 22  ┆ 42125963 ┆ G   ┆ … ┆ gnomADg:amr ┆ null         ┆ 1.0      ┆ splice_polypyr │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ imidine_tract_ │\n",
       "│              ┆     ┆          ┆     ┆   ┆             ┆              ┆          ┆ va…            │\n",
       "└──────────────┴─────┴──────────┴─────┴───┴─────────────┴──────────────┴──────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved variant data to '../data/processed/CYP2D6-pop-vars.parquet'.\n"
     ]
    }
   ],
   "source": [
    "def fetch_variant_frequencies(variant_ids, species=\"human\", batch_size=200, min_interval=0.25):\n",
    "    \"\"\" \"\n",
    "    Fetch variant frequencies from the Ensembl REST API for a given gene.\n",
    "    The maximum number of variants that can be queried at once is 200.\n",
    "    \"\"\"\n",
    "    assert batch_size <= 200, \"Batch size cannot exceed 200.\"\n",
    "\n",
    "    params = {\"pops\": True, \"phenotypes\": True}\n",
    "\n",
    "    BASE = \"https://rest.ensembl.org/\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "    endpoint = \"variation/\" + species\n",
    "\n",
    "    url = BASE + endpoint\n",
    "\n",
    "    size_df = len(variant_ids)\n",
    "\n",
    "    last_request_time = 0.0\n",
    "    collected_vars = {}\n",
    "    for i, batch in enumerate(chunks(variant_ids, batch_size), start=1):\n",
    "        current_progress = min(i * batch_size, size_df)\n",
    "        print(f\"\\rProgress: {current_progress}/{size_df} variants\", end=\"\", flush=True)\n",
    "        # Rate limiting requests\n",
    "        elapsed_time = time.time() - last_request_time\n",
    "        if elapsed_time < min_interval:\n",
    "            time.sleep(min_interval - elapsed_time)\n",
    "\n",
    "        r = requests.post(url, params=params, headers=headers, json={\"ids\": batch})\n",
    "        last_request_time = time.time()\n",
    "\n",
    "        try:\n",
    "            r.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(\"Unable to fetch variants.\")\n",
    "            print(\"API Error:\", e)\n",
    "            return None\n",
    "\n",
    "        collected_vars.update(r.json())\n",
    "\n",
    "    return collected_vars\n",
    "\n",
    "\n",
    "variants = fetch_variant_frequencies(variant_ids=df_vars[\"id\"].to_list())\n",
    "\n",
    "# Convert fetched population frequencies into long format\n",
    "pop_vars = defaultdict(list)\n",
    "for var_id, var_data in variants.items():\n",
    "    f_minor_allele = var_data.get(\"minor_allele\", None)\n",
    "    f_most_severe_consequence = var_data.get(\"most_severe_consequence\", None)\n",
    "    if \"populations\" in var_data:\n",
    "        for pop in var_data[\"populations\"]:\n",
    "            pop_vars[\"id\"].append(var_id)\n",
    "            pop_vars[\"population\"].append(pop[\"population\"])\n",
    "            pop_vars[\"minor_allele\"].append(f_minor_allele)\n",
    "            pop_vars[\"MAF\"].append(pop[\"frequency\"])\n",
    "            pop_vars[\"most_severe_consequence\"].append(f_most_severe_consequence)\n",
    "\n",
    "df_var_freqs = pl.DataFrame(pop_vars, strict=False)\n",
    "\n",
    "# Join long format frequencies to variant data\n",
    "df_merged = df_vars.join(df_var_freqs, on=\"id\", how=\"left\")\n",
    "display(df_merged.head())\n",
    "\n",
    "# Write to Parquet file\n",
    "out_path = f\"../data/processed/{GENE_ID}-pop-vars.parquet\"\n",
    "df_merged.write_parquet(out_path)\n",
    "print(f\"Saved variant data to '{out_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
